Dataset is copied to /tmp
Encoder: FROZEN WEIGHTS
Start Training
use checkpointcheckpoints/tightrope_encoder_ep_14
[1,    10] loss: 6.694
[1,    20] loss: 6.692
[1,    30] loss: 6.698
[1,    40] loss: 6.695
[1,    50] loss: 6.696
[1,    60] loss: 6.697
[1,    70] loss: 6.694
[1,    80] loss: 6.693
[1,    90] loss: 6.694
[1,   100] loss: 6.695
[1] Validation loss: 6.690, Accuracy: 0.12%
[2,    10] loss: 6.693
[2,    20] loss: 6.689
[2,    30] loss: 6.689
[2,    40] loss: 6.687
[2,    50] loss: 6.687
[2,    60] loss: 6.687
[2,    70] loss: 6.683
[2,    80] loss: 6.674
[2,    90] loss: 6.680
[2,   100] loss: 6.677
[2] Validation loss: 6.664, Accuracy: 0.16%
[3,    10] loss: 6.656
[3,    20] loss: 6.652
[3,    30] loss: 6.636
[3,    40] loss: 6.634
[3,    50] loss: 6.618
[3,    60] loss: 6.628
[3,    70] loss: 6.602
[3,    80] loss: 6.602
[3,    90] loss: 6.607
[3,   100] loss: 6.580
[3] Validation loss: 6.592, Accuracy: 0.26%
[4,    10] loss: 6.570
[4,    20] loss: 6.535
[4,    30] loss: 6.559
[4,    40] loss: 6.547
[4,    50] loss: 6.544
[4,    60] loss: 6.559
[4,    70] loss: 6.560
[4,    80] loss: 6.567
[4,    90] loss: 6.537
[4,   100] loss: 6.558
[4] Validation loss: 6.549, Accuracy: 0.31%
[5,    10] loss: 6.518
[5,    20] loss: 6.524
[5,    30] loss: 6.529
[5,    40] loss: 6.519
[5,    50] loss: 6.521
[5,    60] loss: 6.519
[5,    70] loss: 6.513
[5,    80] loss: 6.506
[5,    90] loss: 6.507
[5,   100] loss: 6.492
[5] Validation loss: 6.529, Accuracy: 0.41%
[6,    10] loss: 6.482
[6,    20] loss: 6.490
[6,    30] loss: 6.488
[6,    40] loss: 6.485
[6,    50] loss: 6.464
[6,    60] loss: 6.474
[6,    70] loss: 6.481
[6,    80] loss: 6.469
[6,    90] loss: 6.477
[6,   100] loss: 6.486
[6] Validation loss: 6.504, Accuracy: 0.50%
[7,    10] loss: 6.433
[7,    20] loss: 6.457
[7,    30] loss: 6.442
[7,    40] loss: 6.444
[7,    50] loss: 6.437
[7,    60] loss: 6.473
[7,    70] loss: 6.441
[7,    80] loss: 6.442
[7,    90] loss: 6.448
[7,   100] loss: 6.431
[7] Validation loss: 6.483, Accuracy: 0.57%
[8,    10] loss: 6.401
[8,    20] loss: 6.398
[8,    30] loss: 6.412
[8,    40] loss: 6.413
[8,    50] loss: 6.412
[8,    60] loss: 6.447
[8,    70] loss: 6.422
[8,    80] loss: 6.386
[8,    90] loss: 6.415
[8,   100] loss: 6.412
[8] Validation loss: 6.460, Accuracy: 0.62%
[9,    10] loss: 6.369
[9,    20] loss: 6.371
[9,    30] loss: 6.371
[9,    40] loss: 6.370
[9,    50] loss: 6.366
[9,    60] loss: 6.373
[9,    70] loss: 6.389
[9,    80] loss: 6.395
[9,    90] loss: 6.389
[9,   100] loss: 6.369
[9] Validation loss: 6.439, Accuracy: 0.77%
[10,    10] loss: 6.324
[10,    20] loss: 6.362
[10,    30] loss: 6.310
[10,    40] loss: 6.332
[10,    50] loss: 6.353
[10,    60] loss: 6.339
[10,    70] loss: 6.380
[10,    80] loss: 6.379
[10,    90] loss: 6.348
[10,   100] loss: 6.352
[10] Validation loss: 6.425, Accuracy: 0.79%
[11,    10] loss: 6.312
[11,    20] loss: 6.330
[11,    30] loss: 6.306
[11,    40] loss: 6.305
[11,    50] loss: 6.321
[11,    60] loss: 6.333
[11,    70] loss: 6.321
[11,    80] loss: 6.325
[11,    90] loss: 6.320
[11,   100] loss: 6.356
[11] Validation loss: 6.411, Accuracy: 0.89%
[12,    10] loss: 6.308
[12,    20] loss: 6.300
[12,    30] loss: 6.278
[12,    40] loss: 6.262
[12,    50] loss: 6.310
[12,    60] loss: 6.299
[12,    70] loss: 6.313
[12,    80] loss: 6.300
[12,    90] loss: 6.304
[12,   100] loss: 6.275
[12] Validation loss: 6.405, Accuracy: 0.97%
[13,    10] loss: 6.258
[13,    20] loss: 6.295
[13,    30] loss: 6.249
[13,    40] loss: 6.257
[13,    50] loss: 6.297
[13,    60] loss: 6.292
[13,    70] loss: 6.291
[13,    80] loss: 6.301
[13,    90] loss: 6.275
[13,   100] loss: 6.262
[13] Validation loss: 6.397, Accuracy: 0.92%
[14,    10] loss: 6.228
[14,    20] loss: 6.236
[14,    30] loss: 6.232
[14,    40] loss: 6.251
[14,    50] loss: 6.266
[14,    60] loss: 6.275
[14,    70] loss: 6.281
[14,    80] loss: 6.270
[14,    90] loss: 6.294
[14,   100] loss: 6.240
[14] Validation loss: 6.384, Accuracy: 0.95%
[15,    10] loss: 6.198
[15,    20] loss: 6.180
[15,    30] loss: 6.233
[15,    40] loss: 6.234
[15,    50] loss: 6.244
[15,    60] loss: 6.248
[15,    70] loss: 6.295
[15,    80] loss: 6.260
[15,    90] loss: 6.270
[15,   100] loss: 6.265
[15] Validation loss: 6.373, Accuracy: 1.00%
[16,    10] loss: 6.181
[16,    20] loss: 6.211
[16,    30] loss: 6.177
[16,    40] loss: 6.248
[16,    50] loss: 6.200
[16,    60] loss: 6.194
[16,    70] loss: 6.255
[16,    80] loss: 6.219
[16,    90] loss: 6.271
[16,   100] loss: 6.279
[16] Validation loss: 6.360, Accuracy: 1.14%
[17,    10] loss: 6.186
[17,    20] loss: 6.210
[17,    30] loss: 6.209
[17,    40] loss: 6.190
[17,    50] loss: 6.177
[17,    60] loss: 6.256
[17,    70] loss: 6.216
[17,    80] loss: 6.234
[17,    90] loss: 6.221
[17,   100] loss: 6.198
[17] Validation loss: 6.359, Accuracy: 1.21%
[18,    10] loss: 6.168
[18,    20] loss: 6.171
[18,    30] loss: 6.200
[18,    40] loss: 6.200
[18,    50] loss: 6.197
[18,    60] loss: 6.190
[18,    70] loss: 6.209
[18,    80] loss: 6.186
[18,    90] loss: 6.187
[18,   100] loss: 6.202
[18] Validation loss: 6.358, Accuracy: 1.20%
[19,    10] loss: 6.184
[19,    20] loss: 6.157
[19,    30] loss: 6.149
[19,    40] loss: 6.186
[19,    50] loss: 6.183
[19,    60] loss: 6.173
[19,    70] loss: 6.195
[19,    80] loss: 6.172
[19,    90] loss: 6.194
[19,   100] loss: 6.206
[19] Validation loss: 6.346, Accuracy: 1.30%
[20,    10] loss: 6.149
[20,    20] loss: 6.144
[20,    30] loss: 6.119
[20,    40] loss: 6.114
[20,    50] loss: 6.168
[20,    60] loss: 6.189
[20,    70] loss: 6.180
[20,    80] loss: 6.198
[20,    90] loss: 6.180
[20,   100] loss: 6.214
[20] Validation loss: 6.337, Accuracy: 1.27%
[21,    10] loss: 6.135
[21,    20] loss: 6.163
[21,    30] loss: 6.162
[21,    40] loss: 6.147
[21,    50] loss: 6.135
[21,    60] loss: 6.137
[21,    70] loss: 6.115
[21,    80] loss: 6.185
[21,    90] loss: 6.146
[21,   100] loss: 6.178
[21] Validation loss: 6.333, Accuracy: 1.26%
[22,    10] loss: 6.117
[22,    20] loss: 6.122
[22,    30] loss: 6.135
[22,    40] loss: 6.104
[22,    50] loss: 6.131
[22,    60] loss: 6.142
[22,    70] loss: 6.127
[22,    80] loss: 6.151
[22,    90] loss: 6.170
[22,   100] loss: 6.149
[22] Validation loss: 6.331, Accuracy: 1.34%
[23,    10] loss: 6.092
[23,    20] loss: 6.101
[23,    30] loss: 6.105
[23,    40] loss: 6.144
[23,    50] loss: 6.122
[23,    60] loss: 6.123
[23,    70] loss: 6.162
[23,    80] loss: 6.110
[23,    90] loss: 6.145
[23,   100] loss: 6.136
[23] Validation loss: 6.326, Accuracy: 1.38%
[24,    10] loss: 6.096
[24,    20] loss: 6.078
[24,    30] loss: 6.077
[24,    40] loss: 6.129
[24,    50] loss: 6.126
[24,    60] loss: 6.147
[24,    70] loss: 6.083
[24,    80] loss: 6.128
[24,    90] loss: 6.146
[24,   100] loss: 6.153
[24] Validation loss: 6.306, Accuracy: 1.45%
[25,    10] loss: 6.088
[25,    20] loss: 6.090
[25,    30] loss: 6.126
[25,    40] loss: 6.069
[25,    50] loss: 6.098
[25,    60] loss: 6.117
[25,    70] loss: 6.115
[25,    80] loss: 6.090
[25,    90] loss: 6.083
[25,   100] loss: 6.099
[25] Validation loss: 6.318, Accuracy: 1.41%
[26,    10] loss: 6.062
[26,    20] loss: 6.067
[26,    30] loss: 6.077
[26,    40] loss: 6.083
[26,    50] loss: 6.109
[26,    60] loss: 6.094
[26,    70] loss: 6.092
[26,    80] loss: 6.073
[26,    90] loss: 6.093
[26,   100] loss: 6.110
[26] Validation loss: 6.307, Accuracy: 1.41%
[27,    10] loss: 6.056
[27,    20] loss: 6.072
[27,    30] loss: 6.058
[27,    40] loss: 6.079
[27,    50] loss: 6.050
[27,    60] loss: 6.094
[27,    70] loss: 6.040
[27,    80] loss: 6.049
[27,    90] loss: 6.099
[27,   100] loss: 6.125
[27] Validation loss: 6.302, Accuracy: 1.32%
[28,    10] loss: 6.038
[28,    20] loss: 6.070
[28,    30] loss: 6.016
[28,    40] loss: 6.069
[28,    50] loss: 6.072
[28,    60] loss: 6.052
[28,    70] loss: 6.067
[28,    80] loss: 6.085
[28,    90] loss: 6.065
[28,   100] loss: 6.095
[28] Validation loss: 6.298, Accuracy: 1.53%
[29,    10] loss: 6.026
[29,    20] loss: 6.051
[29,    30] loss: 6.079
[29,    40] loss: 6.014
[29,    50] loss: 6.048
[29,    60] loss: 6.056
[29,    70] loss: 6.092
[29,    80] loss: 6.045
[29,    90] loss: 6.057
[29,   100] loss: 6.075
[29] Validation loss: 6.288, Accuracy: 1.46%
[30,    10] loss: 5.991
[30,    20] loss: 6.030
[30,    30] loss: 6.064
[30,    40] loss: 6.038
[30,    50] loss: 6.065
[30,    60] loss: 6.046
[30,    70] loss: 6.060
[30,    80] loss: 6.029
[30,    90] loss: 6.071
[30,   100] loss: 6.063
[30] Validation loss: 6.283, Accuracy: 1.45%
[31,    10] loss: 5.989
[31,    20] loss: 6.019
[31,    30] loss: 6.006
[31,    40] loss: 6.029
[31,    50] loss: 6.033
[31,    60] loss: 6.031
[31,    70] loss: 6.038
[31,    80] loss: 6.073
[31,    90] loss: 6.058
[31,   100] loss: 6.061
[31] Validation loss: 6.274, Accuracy: 1.50%
[32,    10] loss: 5.964
[32,    20] loss: 5.982
[32,    30] loss: 6.048
[32,    40] loss: 6.007
[32,    50] loss: 6.039
[32,    60] loss: 6.022
[32,    70] loss: 6.069
[32,    80] loss: 6.026
[32,    90] loss: 6.045
[32,   100] loss: 6.036
[32] Validation loss: 6.279, Accuracy: 1.58%
[33,    10] loss: 5.998
[33,    20] loss: 5.963
[33,    30] loss: 6.014
[33,    40] loss: 6.008
[33,    50] loss: 5.966
[33,    60] loss: 6.033
[33,    70] loss: 6.049
[33,    80] loss: 6.057
[33,    90] loss: 6.059
[33,   100] loss: 6.051
[33] Validation loss: 6.265, Accuracy: 1.55%
[34,    10] loss: 5.995
[34,    20] loss: 5.978
[34,    30] loss: 5.994
[34,    40] loss: 6.025
[34,    50] loss: 6.002
[34,    60] loss: 6.023
[34,    70] loss: 6.015
[34,    80] loss: 6.023
[34,    90] loss: 6.035
[34,   100] loss: 6.019
[34] Validation loss: 6.271, Accuracy: 1.57%
[35,    10] loss: 5.999
[35,    20] loss: 5.931
[35,    30] loss: 5.978
[35,    40] loss: 5.977
[35,    50] loss: 6.028
[35,    60] loss: 6.003
[35,    70] loss: 6.017
[35,    80] loss: 6.068
[35,    90] loss: 6.005
[35,   100] loss: 6.026
[35] Validation loss: 6.260, Accuracy: 1.59%
[36,    10] loss: 5.982
[36,    20] loss: 5.936
[36,    30] loss: 5.955
[36,    40] loss: 5.985
[36,    50] loss: 5.991
[36,    60] loss: 6.018
[36,    70] loss: 6.022
[36,    80] loss: 5.983
[36,    90] loss: 5.997
[36,   100] loss: 6.058
[36] Validation loss: 6.266, Accuracy: 1.62%
[37,    10] loss: 5.991
[37,    20] loss: 5.970
[37,    30] loss: 5.982
[37,    40] loss: 5.993
[37,    50] loss: 5.994
[37,    60] loss: 5.970
[37,    70] loss: 5.965
[37,    80] loss: 5.991
[37,    90] loss: 6.008
[37,   100] loss: 6.006
[37] Validation loss: 6.264, Accuracy: 1.64%
[38,    10] loss: 5.945
[38,    20] loss: 5.981
[38,    30] loss: 5.937
[38,    40] loss: 5.954
[38,    50] loss: 6.031
[38,    60] loss: 5.967
[38,    70] loss: 5.956
[38,    80] loss: 6.041
[38,    90] loss: 5.978
[38,   100] loss: 6.013
[38] Validation loss: 6.259, Accuracy: 1.61%
[39,    10] loss: 5.913
[39,    20] loss: 5.929
[39,    30] loss: 5.950
[39,    40] loss: 5.955
[39,    50] loss: 6.000
[39,    60] loss: 6.017
[39,    70] loss: 6.013
[39,    80] loss: 5.974
[39,    90] loss: 6.000
[39,   100] loss: 5.997
[39] Validation loss: 6.263, Accuracy: 1.64%
[40,    10] loss: 5.981
[40,    20] loss: 5.929
[40,    30] loss: 5.938
[40,    40] loss: 5.932
[40,    50] loss: 5.967
[40,    60] loss: 5.938
[40,    70] loss: 5.981
[40,    80] loss: 6.049
[40,    90] loss: 5.938
[40,   100] loss: 6.012
[40] Validation loss: 6.261, Accuracy: 1.67%
[41,    10] loss: 5.951
[41,    20] loss: 5.950
[41,    30] loss: 5.976
[41,    40] loss: 5.939
[41,    50] loss: 5.965
[41,    60] loss: 6.001
[41,    70] loss: 5.959
[41,    80] loss: 5.910
[41,    90] loss: 5.981
[41,   100] loss: 5.965
[41] Validation loss: 6.267, Accuracy: 1.66%
[42,    10] loss: 5.922
[42,    20] loss: 5.951
[42,    30] loss: 5.920
[42,    40] loss: 5.948
[42,    50] loss: 5.962
[42,    60] loss: 5.941
[42,    70] loss: 5.948
[42,    80] loss: 5.960
[42,    90] loss: 5.974
[42,   100] loss: 6.018
[42] Validation loss: 6.262, Accuracy: 1.66%
[43,    10] loss: 5.888
[43,    20] loss: 5.899
[43,    30] loss: 5.903
[43,    40] loss: 5.913
[43,    50] loss: 5.964
[43,    60] loss: 5.992
[43,    70] loss: 5.962
[43,    80] loss: 5.993
[43,    90] loss: 6.011
[43,   100] loss: 5.954
[43] Validation loss: 6.256, Accuracy: 1.63%
[44,    10] loss: 5.913
[44,    20] loss: 5.913
[44,    30] loss: 5.915
[44,    40] loss: 5.914
[44,    50] loss: 5.927
[44,    60] loss: 5.971
[44,    70] loss: 5.958
[44,    80] loss: 5.957
[44,    90] loss: 5.952
[44,   100] loss: 5.975
[44] Validation loss: 6.255, Accuracy: 1.71%
[45,    10] loss: 5.902
[45,    20] loss: 5.909
[45,    30] loss: 5.931
[45,    40] loss: 5.926
[45,    50] loss: 5.909
[45,    60] loss: 5.959
[45,    70] loss: 5.994
[45,    80] loss: 5.930
[45,    90] loss: 5.951
[45,   100] loss: 5.952
[45] Validation loss: 6.259, Accuracy: 1.72%
[46,    10] loss: 5.902
[46,    20] loss: 5.919
[46,    30] loss: 5.899
[46,    40] loss: 5.947
[46,    50] loss: 5.925
[46,    60] loss: 5.927
[46,    70] loss: 5.951
[46,    80] loss: 5.936
[46,    90] loss: 5.971
[46,   100] loss: 5.958
[46] Validation loss: 6.258, Accuracy: 1.69%
[47,    10] loss: 5.907
[47,    20] loss: 5.926
[47,    30] loss: 5.888
[47,    40] loss: 5.935
[47,    50] loss: 5.938
[47,    60] loss: 5.959
[47,    70] loss: 5.897
[47,    80] loss: 5.956
[47,    90] loss: 5.933
[47,   100] loss: 5.933
[47] Validation loss: 6.267, Accuracy: 1.68%
[48,    10] loss: 5.923
[48,    20] loss: 5.872
[48,    30] loss: 5.891
[48,    40] loss: 5.928
[48,    50] loss: 5.947
[48,    60] loss: 5.929
[48,    70] loss: 5.912
[48,    80] loss: 5.951
[48,    90] loss: 5.965
[48,   100] loss: 5.899
[48] Validation loss: 6.253, Accuracy: 1.63%
[49,    10] loss: 5.868
[49,    20] loss: 5.908
[49,    30] loss: 5.895
[49,    40] loss: 5.876
[49,    50] loss: 5.876
[49,    60] loss: 5.925
[49,    70] loss: 5.958
[49,    80] loss: 5.950
[49,    90] loss: 5.940
[49,   100] loss: 5.972
[49] Validation loss: 6.258, Accuracy: 1.66%
[50,    10] loss: 5.899
[50,    20] loss: 5.898
[50,    30] loss: 5.884
[50,    40] loss: 5.923
[50,    50] loss: 5.932
[50,    60] loss: 5.933
[50,    70] loss: 5.903
[50,    80] loss: 5.900
[50,    90] loss: 5.927
[50,   100] loss: 5.946
[50] Validation loss: 6.269, Accuracy: 1.71%
Finished Training
Time elapsed: 2896.858256591
Saved checkpoint to checkpoints/small_classifier/frozen_encoder_classifier.pth
