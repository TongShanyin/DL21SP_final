Dataset is copied to /tmp
Encoder: FROZEN WEIGHTS
Start Training
use checkpointcheckpoints/tightrope_encoder_ep_14
[1,    10] loss: 6.689
[1,    20] loss: 6.690
[1,    30] loss: 6.691
[1,    40] loss: 6.690
[1,    50] loss: 6.692
[1,    60] loss: 6.687
[1,    70] loss: 6.688
[1,    80] loss: 6.688
[1,    90] loss: 6.687
[1,   100] loss: 6.688
[1] Validation loss: 6.682, Accuracy: 0.26%
[2,    10] loss: 6.679
[2,    20] loss: 6.671
[2,    30] loss: 6.655
[2,    40] loss: 6.652
[2,    50] loss: 6.634
[2,    60] loss: 6.632
[2,    70] loss: 6.622
[2,    80] loss: 6.613
[2,    90] loss: 6.597
[2,   100] loss: 6.597
[2] Validation loss: 6.575, Accuracy: 0.29%
[3,    10] loss: 6.546
[3,    20] loss: 6.558
[3,    30] loss: 6.530
[3,    40] loss: 6.551
[3,    50] loss: 6.531
[3,    60] loss: 6.532
[3,    70] loss: 6.528
[3,    80] loss: 6.515
[3,    90] loss: 6.520
[3,   100] loss: 6.492
[3] Validation loss: 6.508, Accuracy: 0.45%
[4,    10] loss: 6.457
[4,    20] loss: 6.460
[4,    30] loss: 6.435
[4,    40] loss: 6.459
[4,    50] loss: 6.437
[4,    60] loss: 6.444
[4,    70] loss: 6.431
[4,    80] loss: 6.440
[4,    90] loss: 6.433
[4,   100] loss: 6.434
[4] Validation loss: 6.439, Accuracy: 0.73%
[5,    10] loss: 6.365
[5,    20] loss: 6.361
[5,    30] loss: 6.344
[5,    40] loss: 6.407
[5,    50] loss: 6.351
[5,    60] loss: 6.341
[5,    70] loss: 6.360
[5,    80] loss: 6.360
[5,    90] loss: 6.361
[5,   100] loss: 6.322
[5] Validation loss: 6.376, Accuracy: 0.96%
[6,    10] loss: 6.267
[6,    20] loss: 6.275
[6,    30] loss: 6.280
[6,    40] loss: 6.310
[6,    50] loss: 6.324
[6,    60] loss: 6.308
[6,    70] loss: 6.298
[6,    80] loss: 6.300
[6,    90] loss: 6.293
[6,   100] loss: 6.275
[6] Validation loss: 6.344, Accuracy: 0.95%
[7,    10] loss: 6.229
[7,    20] loss: 6.235
[7,    30] loss: 6.239
[7,    40] loss: 6.253
[7,    50] loss: 6.257
[7,    60] loss: 6.253
[7,    70] loss: 6.244
[7,    80] loss: 6.262
[7,    90] loss: 6.223
[7,   100] loss: 6.259
[7] Validation loss: 6.317, Accuracy: 1.06%
[8,    10] loss: 6.190
[8,    20] loss: 6.183
[8,    30] loss: 6.190
[8,    40] loss: 6.237
[8,    50] loss: 6.201
[8,    60] loss: 6.208
[8,    70] loss: 6.208
[8,    80] loss: 6.221
[8,    90] loss: 6.210
[8,   100] loss: 6.195
[8] Validation loss: 6.296, Accuracy: 1.23%
[9,    10] loss: 6.113
[9,    20] loss: 6.123
[9,    30] loss: 6.160
[9,    40] loss: 6.161
[9,    50] loss: 6.183
[9,    60] loss: 6.169
[9,    70] loss: 6.174
[9,    80] loss: 6.208
[9,    90] loss: 6.170
[9,   100] loss: 6.157
[9] Validation loss: 6.278, Accuracy: 1.27%
[10,    10] loss: 6.096
[10,    20] loss: 6.103
[10,    30] loss: 6.123
[10,    40] loss: 6.106
[10,    50] loss: 6.113
[10,    60] loss: 6.106
[10,    70] loss: 6.144
[10,    80] loss: 6.160
[10,    90] loss: 6.163
[10,   100] loss: 6.133
[10] Validation loss: 6.262, Accuracy: 1.46%
[11,    10] loss: 6.046
[11,    20] loss: 6.089
[11,    30] loss: 6.078
[11,    40] loss: 6.087
[11,    50] loss: 6.103
[11,    60] loss: 6.076
[11,    70] loss: 6.066
[11,    80] loss: 6.136
[11,    90] loss: 6.121
[11,   100] loss: 6.095
[11] Validation loss: 6.259, Accuracy: 1.51%
[12,    10] loss: 5.999
[12,    20] loss: 6.047
[12,    30] loss: 6.051
[12,    40] loss: 6.041
[12,    50] loss: 6.072
[12,    60] loss: 6.063
[12,    70] loss: 6.084
[12,    80] loss: 6.089
[12,    90] loss: 6.105
[12,   100] loss: 6.057
[12] Validation loss: 6.254, Accuracy: 1.44%
[13,    10] loss: 5.999
[13,    20] loss: 5.972
[13,    30] loss: 6.010
[13,    40] loss: 6.046
[13,    50] loss: 6.068
[13,    60] loss: 6.043
[13,    70] loss: 6.077
[13,    80] loss: 6.056
[13,    90] loss: 6.041
[13,   100] loss: 6.082
[13] Validation loss: 6.261, Accuracy: 1.50%
[14,    10] loss: 5.987
[14,    20] loss: 5.940
[14,    30] loss: 5.981
[14,    40] loss: 6.019
[14,    50] loss: 6.004
[14,    60] loss: 6.014
[14,    70] loss: 6.028
[14,    80] loss: 6.054
[14,    90] loss: 6.041
[14,   100] loss: 6.035
[14] Validation loss: 6.240, Accuracy: 1.61%
[15,    10] loss: 5.966
[15,    20] loss: 5.948
[15,    30] loss: 5.988
[15,    40] loss: 5.994
[15,    50] loss: 5.985
[15,    60] loss: 6.023
[15,    70] loss: 5.999
[15,    80] loss: 5.995
[15,    90] loss: 6.007
[15,   100] loss: 5.996
[15] Validation loss: 6.246, Accuracy: 1.64%
[16,    10] loss: 5.957
[16,    20] loss: 5.928
[16,    30] loss: 5.930
[16,    40] loss: 5.990
[16,    50] loss: 5.967
[16,    60] loss: 5.954
[16,    70] loss: 5.932
[16,    80] loss: 5.975
[16,    90] loss: 5.970
[16,   100] loss: 5.984
[16] Validation loss: 6.237, Accuracy: 1.71%
[17,    10] loss: 5.910
[17,    20] loss: 5.871
[17,    30] loss: 5.942
[17,    40] loss: 5.938
[17,    50] loss: 5.934
[17,    60] loss: 5.914
[17,    70] loss: 5.967
[17,    80] loss: 5.989
[17,    90] loss: 5.966
[17,   100] loss: 5.961
[17] Validation loss: 6.247, Accuracy: 1.78%
[18,    10] loss: 5.934
[18,    20] loss: 5.877
[18,    30] loss: 5.906
[18,    40] loss: 5.897
[18,    50] loss: 5.920
[18,    60] loss: 5.921
[18,    70] loss: 5.919
[18,    80] loss: 5.954
[18,    90] loss: 5.933
[18,   100] loss: 5.935
[18] Validation loss: 6.245, Accuracy: 1.76%
[19,    10] loss: 5.860
[19,    20] loss: 5.882
[19,    30] loss: 5.892
[19,    40] loss: 5.903
[19,    50] loss: 5.895
[19,    60] loss: 5.903
[19,    70] loss: 5.903
[19,    80] loss: 5.906
[19,    90] loss: 5.902
[19,   100] loss: 5.907
[19] Validation loss: 6.259, Accuracy: 1.70%
[20,    10] loss: 5.867
[20,    20] loss: 5.866
[20,    30] loss: 5.852
[20,    40] loss: 5.858
[20,    50] loss: 5.890
[20,    60] loss: 5.888
[20,    70] loss: 5.879
[20,    80] loss: 5.859
[20,    90] loss: 5.900
[20,   100] loss: 5.916
[20] Validation loss: 6.261, Accuracy: 1.80%
[21,    10] loss: 5.790
[21,    20] loss: 5.814
[21,    30] loss: 5.818
[21,    40] loss: 5.832
[21,    50] loss: 5.867
[21,    60] loss: 5.870
[21,    70] loss: 5.903
[21,    80] loss: 5.952
[21,    90] loss: 5.884
[21,   100] loss: 5.863
[21] Validation loss: 6.281, Accuracy: 1.80%
[22,    10] loss: 5.806
[22,    20] loss: 5.825
[22,    30] loss: 5.809
[22,    40] loss: 5.857
[22,    50] loss: 5.819
[22,    60] loss: 5.872
[22,    70] loss: 5.845
[22,    80] loss: 5.895
[22,    90] loss: 5.854
[22,   100] loss: 5.847
[22] Validation loss: 6.292, Accuracy: 1.69%
[23,    10] loss: 5.799
[23,    20] loss: 5.791
[23,    30] loss: 5.777
[23,    40] loss: 5.806
[23,    50] loss: 5.821
[23,    60] loss: 5.852
[23,    70] loss: 5.832
[23,    80] loss: 5.869
[23,    90] loss: 5.842
[23,   100] loss: 5.853
[23] Validation loss: 6.291, Accuracy: 1.74%
[24,    10] loss: 5.757
[24,    20] loss: 5.798
[24,    30] loss: 5.776
[24,    40] loss: 5.822
[24,    50] loss: 5.808
[24,    60] loss: 5.829
[24,    70] loss: 5.821
[24,    80] loss: 5.784
[24,    90] loss: 5.819
[24,   100] loss: 5.814
[24] Validation loss: 6.298, Accuracy: 1.82%
[25,    10] loss: 5.742
[25,    20] loss: 5.802
[25,    30] loss: 5.742
[25,    40] loss: 5.805
[25,    50] loss: 5.728
[25,    60] loss: 5.798
[25,    70] loss: 5.782
[25,    80] loss: 5.825
[25,    90] loss: 5.833
[25,   100] loss: 5.840
[25] Validation loss: 6.301, Accuracy: 1.75%
[26,    10] loss: 5.767
[26,    20] loss: 5.718
[26,    30] loss: 5.749
[26,    40] loss: 5.751
[26,    50] loss: 5.734
[26,    60] loss: 5.793
[26,    70] loss: 5.744
[26,    80] loss: 5.771
[26,    90] loss: 5.836
[26,   100] loss: 5.842
[26] Validation loss: 6.302, Accuracy: 1.72%
[27,    10] loss: 5.660
[27,    20] loss: 5.712
[27,    30] loss: 5.729
[27,    40] loss: 5.708
[27,    50] loss: 5.777
[27,    60] loss: 5.768
[27,    70] loss: 5.767
[27,    80] loss: 5.795
[27,    90] loss: 5.796
[27,   100] loss: 5.810
[27] Validation loss: 6.307, Accuracy: 1.84%
[28,    10] loss: 5.660
[28,    20] loss: 5.666
[28,    30] loss: 5.754
[28,    40] loss: 5.741
[28,    50] loss: 5.676
[28,    60] loss: 5.767
[28,    70] loss: 5.734
[28,    80] loss: 5.741
[28,    90] loss: 5.783
[28,   100] loss: 5.807
[28] Validation loss: 6.317, Accuracy: 1.77%
[29,    10] loss: 5.714
[29,    20] loss: 5.685
[29,    30] loss: 5.672
[29,    40] loss: 5.657
[29,    50] loss: 5.743
[29,    60] loss: 5.716
[29,    70] loss: 5.722
[29,    80] loss: 5.759
[29,    90] loss: 5.766
[29,   100] loss: 5.742
[29] Validation loss: 6.333, Accuracy: 1.82%
[30,    10] loss: 5.610
[30,    20] loss: 5.678
[30,    30] loss: 5.671
[30,    40] loss: 5.679
[30,    50] loss: 5.753
[30,    60] loss: 5.673
[30,    70] loss: 5.740
[30,    80] loss: 5.736
[30,    90] loss: 5.750
[30,   100] loss: 5.766
[30] Validation loss: 6.323, Accuracy: 1.84%
[31,    10] loss: 5.667
[31,    20] loss: 5.639
[31,    30] loss: 5.644
[31,    40] loss: 5.698
[31,    50] loss: 5.711
[31,    60] loss: 5.684
[31,    70] loss: 5.745
[31,    80] loss: 5.666
[31,    90] loss: 5.697
[31,   100] loss: 5.717
[31] Validation loss: 6.368, Accuracy: 1.82%
[32,    10] loss: 5.641
[32,    20] loss: 5.640
[32,    30] loss: 5.632
[32,    40] loss: 5.659
[32,    50] loss: 5.683
[32,    60] loss: 5.651
[32,    70] loss: 5.717
[32,    80] loss: 5.698
[32,    90] loss: 5.695
[32,   100] loss: 5.700
[32] Validation loss: 6.372, Accuracy: 1.85%
[33,    10] loss: 5.653
[33,    20] loss: 5.652
[33,    30] loss: 5.628
[33,    40] loss: 5.621
[33,    50] loss: 5.655
[33,    60] loss: 5.670
[33,    70] loss: 5.688
[33,    80] loss: 5.649
[33,    90] loss: 5.671
[33,   100] loss: 5.719
[33] Validation loss: 6.359, Accuracy: 1.82%
[34,    10] loss: 5.568
[34,    20] loss: 5.590
[34,    30] loss: 5.620
[34,    40] loss: 5.648
[34,    50] loss: 5.696
[34,    60] loss: 5.640
[34,    70] loss: 5.662
[34,    80] loss: 5.643
[34,    90] loss: 5.666
[34,   100] loss: 5.664
[34] Validation loss: 6.408, Accuracy: 1.85%
[35,    10] loss: 5.566
[35,    20] loss: 5.584
[35,    30] loss: 5.604
[35,    40] loss: 5.582
[35,    50] loss: 5.667
[35,    60] loss: 5.657
[35,    70] loss: 5.665
[35,    80] loss: 5.610
[35,    90] loss: 5.633
[35,   100] loss: 5.687
[35] Validation loss: 6.391, Accuracy: 1.79%
[36,    10] loss: 5.563
[36,    20] loss: 5.556
[36,    30] loss: 5.552
[36,    40] loss: 5.600
[36,    50] loss: 5.584
[36,    60] loss: 5.655
[36,    70] loss: 5.619
[36,    80] loss: 5.616
[36,    90] loss: 5.686
[36,   100] loss: 5.639
[36] Validation loss: 6.399, Accuracy: 1.81%
[37,    10] loss: 5.574
[37,    20] loss: 5.562
[37,    30] loss: 5.538
[37,    40] loss: 5.565
[37,    50] loss: 5.606
[37,    60] loss: 5.605
[37,    70] loss: 5.618
[37,    80] loss: 5.655
[37,    90] loss: 5.624
[37,   100] loss: 5.606
[37] Validation loss: 6.424, Accuracy: 1.73%
[38,    10] loss: 5.550
[38,    20] loss: 5.536
[38,    30] loss: 5.575
[38,    40] loss: 5.560
[38,    50] loss: 5.546
[38,    60] loss: 5.606
[38,    70] loss: 5.545
[38,    80] loss: 5.615
[38,    90] loss: 5.664
[38,   100] loss: 5.599
[38] Validation loss: 6.405, Accuracy: 1.75%
[39,    10] loss: 5.499
[39,    20] loss: 5.546
[39,    30] loss: 5.547
[39,    40] loss: 5.563
[39,    50] loss: 5.578
[39,    60] loss: 5.569
[39,    70] loss: 5.546
[39,    80] loss: 5.608
[39,    90] loss: 5.606
[39,   100] loss: 5.608
[39] Validation loss: 6.422, Accuracy: 1.79%
[40,    10] loss: 5.498
[40,    20] loss: 5.523
[40,    30] loss: 5.544
[40,    40] loss: 5.508
[40,    50] loss: 5.535
[40,    60] loss: 5.495
[40,    70] loss: 5.568
[40,    80] loss: 5.596
[40,    90] loss: 5.602
[40,   100] loss: 5.633
[40] Validation loss: 6.431, Accuracy: 1.89%
[41,    10] loss: 5.432
[41,    20] loss: 5.549
[41,    30] loss: 5.499
[41,    40] loss: 5.556
[41,    50] loss: 5.510
[41,    60] loss: 5.512
[41,    70] loss: 5.532
[41,    80] loss: 5.560
[41,    90] loss: 5.568
[41,   100] loss: 5.590
[41] Validation loss: 6.451, Accuracy: 1.79%
[42,    10] loss: 5.449
[42,    20] loss: 5.479
[42,    30] loss: 5.487
[42,    40] loss: 5.499
[42,    50] loss: 5.508
[42,    60] loss: 5.566
[42,    70] loss: 5.562
[42,    80] loss: 5.571
[42,    90] loss: 5.557
[42,   100] loss: 5.563
[42] Validation loss: 6.451, Accuracy: 1.89%
[43,    10] loss: 5.391
[43,    20] loss: 5.441
[43,    30] loss: 5.550
[43,    40] loss: 5.537
[43,    50] loss: 5.523
[43,    60] loss: 5.542
[43,    70] loss: 5.511
[43,    80] loss: 5.535
[43,    90] loss: 5.548
[43,   100] loss: 5.563
[43] Validation loss: 6.474, Accuracy: 1.98%
[44,    10] loss: 5.455
[44,    20] loss: 5.466
[44,    30] loss: 5.469
[44,    40] loss: 5.507
[44,    50] loss: 5.472
[44,    60] loss: 5.516
[44,    70] loss: 5.527
[44,    80] loss: 5.583
[44,    90] loss: 5.524
[44,   100] loss: 5.535
[44] Validation loss: 6.496, Accuracy: 1.88%
[45,    10] loss: 5.446
[45,    20] loss: 5.454
[45,    30] loss: 5.389
[45,    40] loss: 5.501
[45,    50] loss: 5.454
[45,    60] loss: 5.547
[45,    70] loss: 5.514
[45,    80] loss: 5.536
[45,    90] loss: 5.494
[45,   100] loss: 5.531
[45] Validation loss: 6.522, Accuracy: 1.90%
[46,    10] loss: 5.392
[46,    20] loss: 5.454
[46,    30] loss: 5.392
[46,    40] loss: 5.448
[46,    50] loss: 5.489
[46,    60] loss: 5.495
[46,    70] loss: 5.503
[46,    80] loss: 5.480
[46,    90] loss: 5.577
[46,   100] loss: 5.525
[46] Validation loss: 6.484, Accuracy: 1.89%
[47,    10] loss: 5.375
[47,    20] loss: 5.471
[47,    30] loss: 5.406
[47,    40] loss: 5.405
[47,    50] loss: 5.457
[47,    60] loss: 5.461
[47,    70] loss: 5.457
[47,    80] loss: 5.500
[47,    90] loss: 5.544
[47,   100] loss: 5.492
[47] Validation loss: 6.523, Accuracy: 1.89%
[48,    10] loss: 5.390
[48,    20] loss: 5.424
[48,    30] loss: 5.379
[48,    40] loss: 5.446
[48,    50] loss: 5.432
[48,    60] loss: 5.432
[48,    70] loss: 5.492
[48,    80] loss: 5.476
[48,    90] loss: 5.510
[48,   100] loss: 5.489
[48] Validation loss: 6.538, Accuracy: 1.87%
[49,    10] loss: 5.351
[49,    20] loss: 5.381
[49,    30] loss: 5.444
[49,    40] loss: 5.441
[49,    50] loss: 5.419
[49,    60] loss: 5.439
[49,    70] loss: 5.470
[49,    80] loss: 5.430
[49,    90] loss: 5.493
[49,   100] loss: 5.477
[49] Validation loss: 6.541, Accuracy: 1.83%
[50,    10] loss: 5.360
[50,    20] loss: 5.350
[50,    30] loss: 5.389
[50,    40] loss: 5.413
[50,    50] loss: 5.456
[50,    60] loss: 5.417
[50,    70] loss: 5.472
[50,    80] loss: 5.493
[50,    90] loss: 5.439
[50,   100] loss: 5.481
[50] Validation loss: 6.558, Accuracy: 1.87%
Finished Training
Time elapsed: 2962.8367990780002
Saved checkpoint to checkpoints/small_classifier/frozen_encoder_classifier.pth
