Dataset is copied to /tmp
Start Training
use checkpointcheckpoints/tightrope_4_12/tightrope_encoder_ep_5
[1,    10] loss: 6.689
[1,    20] loss: 6.692
[1,    30] loss: 6.690
[1,    40] loss: 6.689
[1,    50] loss: 6.690
[1,    60] loss: 6.689
[1,    70] loss: 6.690
[1,    80] loss: 6.687
[1,    90] loss: 6.691
[1,   100] loss: 6.690
[1] Validation loss: 6.686, Accuracy: 0.13%
[2,    10] loss: 6.688
[2,    20] loss: 6.684
[2,    30] loss: 6.680
[2,    40] loss: 6.681
[2,    50] loss: 6.666
[2,    60] loss: 6.663
[2,    70] loss: 6.641
[2,    80] loss: 6.623
[2,    90] loss: 6.600
[2,   100] loss: 6.611
[2] Validation loss: 6.584, Accuracy: 0.23%
[3,    10] loss: 6.555
[3,    20] loss: 6.554
[3,    30] loss: 6.552
[3,    40] loss: 6.552
[3,    50] loss: 6.549
[3,    60] loss: 6.552
[3,    70] loss: 6.551
[3,    80] loss: 6.526
[3,    90] loss: 6.541
[3,   100] loss: 6.525
[3] Validation loss: 6.518, Accuracy: 0.47%
[4,    10] loss: 6.471
[4,    20] loss: 6.455
[4,    30] loss: 6.448
[4,    40] loss: 6.461
[4,    50] loss: 6.469
[4,    60] loss: 6.447
[4,    70] loss: 6.494
[4,    80] loss: 6.444
[4,    90] loss: 6.459
[4,   100] loss: 6.447
[4] Validation loss: 6.477, Accuracy: 0.54%
[5,    10] loss: 6.368
[5,    20] loss: 6.397
[5,    30] loss: 6.397
[5,    40] loss: 6.436
[5,    50] loss: 6.413
[5,    60] loss: 6.390
[5,    70] loss: 6.403
[5,    80] loss: 6.412
[5,    90] loss: 6.393
[5,   100] loss: 6.396
[5] Validation loss: 6.456, Accuracy: 0.71%
[6,    10] loss: 6.350
[6,    20] loss: 6.338
[6,    30] loss: 6.326
[6,    40] loss: 6.356
[6,    50] loss: 6.340
[6,    60] loss: 6.368
[6,    70] loss: 6.343
[6,    80] loss: 6.342
[6,    90] loss: 6.345
[6,   100] loss: 6.354
[6] Validation loss: 6.422, Accuracy: 0.82%
[7,    10] loss: 6.262
[7,    20] loss: 6.266
[7,    30] loss: 6.295
[7,    40] loss: 6.286
[7,    50] loss: 6.277
[7,    60] loss: 6.264
[7,    70] loss: 6.295
[7,    80] loss: 6.295
[7,    90] loss: 6.294
[7,   100] loss: 6.268
[7] Validation loss: 6.366, Accuracy: 0.98%
[8,    10] loss: 6.169
[8,    20] loss: 6.189
[8,    30] loss: 6.177
[8,    40] loss: 6.188
[8,    50] loss: 6.209
[8,    60] loss: 6.223
[8,    70] loss: 6.238
[8,    80] loss: 6.217
[8,    90] loss: 6.243
[8,   100] loss: 6.217
[8] Validation loss: 6.329, Accuracy: 1.16%
[9,    10] loss: 6.123
[9,    20] loss: 6.098
[9,    30] loss: 6.131
[9,    40] loss: 6.133
[9,    50] loss: 6.144
[9,    60] loss: 6.175
[9,    70] loss: 6.149
[9,    80] loss: 6.127
[9,    90] loss: 6.158
[9,   100] loss: 6.133
[9] Validation loss: 6.299, Accuracy: 1.28%
[10,    10] loss: 5.995
[10,    20] loss: 6.025
[10,    30] loss: 6.043
[10,    40] loss: 6.050
[10,    50] loss: 6.079
[10,    60] loss: 6.077
[10,    70] loss: 6.131
[10,    80] loss: 6.120
[10,    90] loss: 6.067
[10,   100] loss: 6.070
[10] Validation loss: 6.267, Accuracy: 1.41%
[11,    10] loss: 5.962
[11,    20] loss: 5.942
[11,    30] loss: 5.967
[11,    40] loss: 6.012
[11,    50] loss: 6.040
[11,    60] loss: 6.013
[11,    70] loss: 6.024
[11,    80] loss: 6.012
[11,    90] loss: 5.998
[11,   100] loss: 6.017
[11] Validation loss: 6.249, Accuracy: 1.34%
[12,    10] loss: 5.881
[12,    20] loss: 5.899
[12,    30] loss: 5.915
[12,    40] loss: 5.938
[12,    50] loss: 5.933
[12,    60] loss: 5.958
[12,    70] loss: 5.984
[12,    80] loss: 5.967
[12,    90] loss: 5.958
[12,   100] loss: 5.987
[12] Validation loss: 6.202, Accuracy: 1.62%
[13,    10] loss: 5.811
[13,    20] loss: 5.836
[13,    30] loss: 5.851
[13,    40] loss: 5.937
[13,    50] loss: 5.938
[13,    60] loss: 5.936
[13,    70] loss: 5.913
[13,    80] loss: 5.901
[13,    90] loss: 5.893
[13,   100] loss: 5.883
[13] Validation loss: 6.186, Accuracy: 1.60%
[14,    10] loss: 5.769
[14,    20] loss: 5.826
[14,    30] loss: 5.757
[14,    40] loss: 5.832
[14,    50] loss: 5.854
[14,    60] loss: 5.830
[14,    70] loss: 5.845
[14,    80] loss: 5.830
[14,    90] loss: 5.852
[14,   100] loss: 5.881
[14] Validation loss: 6.209, Accuracy: 1.76%
[15,    10] loss: 5.763
[15,    20] loss: 5.770
[15,    30] loss: 5.764
[15,    40] loss: 5.747
[15,    50] loss: 5.824
[15,    60] loss: 5.771
[15,    70] loss: 5.809
[15,    80] loss: 5.797
[15,    90] loss: 5.776
[15,   100] loss: 5.807
[15] Validation loss: 6.185, Accuracy: 1.93%
[16,    10] loss: 5.659
[16,    20] loss: 5.702
[16,    30] loss: 5.731
[16,    40] loss: 5.732
[16,    50] loss: 5.689
[16,    60] loss: 5.754
[16,    70] loss: 5.723
[16,    80] loss: 5.781
[16,    90] loss: 5.741
[16,   100] loss: 5.806
[16] Validation loss: 6.169, Accuracy: 1.98%
[17,    10] loss: 5.632
[17,    20] loss: 5.597
[17,    30] loss: 5.688
[17,    40] loss: 5.746
[17,    50] loss: 5.658
[17,    60] loss: 5.748
[17,    70] loss: 5.701
[17,    80] loss: 5.712
[17,    90] loss: 5.742
[17,   100] loss: 5.715
[17] Validation loss: 6.139, Accuracy: 2.06%
[18,    10] loss: 5.585
[18,    20] loss: 5.640
[18,    30] loss: 5.638
[18,    40] loss: 5.628
[18,    50] loss: 5.645
[18,    60] loss: 5.619
[18,    70] loss: 5.641
[18,    80] loss: 5.643
[18,    90] loss: 5.659
[18,   100] loss: 5.692
[18] Validation loss: 6.128, Accuracy: 2.17%
[19,    10] loss: 5.547
[19,    20] loss: 5.560
[19,    30] loss: 5.562
[19,    40] loss: 5.578
[19,    50] loss: 5.615
[19,    60] loss: 5.602
[19,    70] loss: 5.640
[19,    80] loss: 5.614
[19,    90] loss: 5.653
[19,   100] loss: 5.642
[19] Validation loss: 6.137, Accuracy: 2.11%
[20,    10] loss: 5.524
[20,    20] loss: 5.542
[20,    30] loss: 5.502
[20,    40] loss: 5.520
[20,    50] loss: 5.570
[20,    60] loss: 5.552
[20,    70] loss: 5.519
[20,    80] loss: 5.569
[20,    90] loss: 5.611
[20,   100] loss: 5.575
[20] Validation loss: 6.150, Accuracy: 2.29%
[21,    10] loss: 5.424
[21,    20] loss: 5.448
[21,    30] loss: 5.468
[21,    40] loss: 5.534
[21,    50] loss: 5.459
[21,    60] loss: 5.510
[21,    70] loss: 5.582
[21,    80] loss: 5.553
[21,    90] loss: 5.569
[21,   100] loss: 5.542
[21] Validation loss: 6.117, Accuracy: 2.45%
[22,    10] loss: 5.399
[22,    20] loss: 5.426
[22,    30] loss: 5.431
[22,    40] loss: 5.417
[22,    50] loss: 5.423
[22,    60] loss: 5.475
[22,    70] loss: 5.538
[22,    80] loss: 5.536
[22,    90] loss: 5.521
[22,   100] loss: 5.544
[22] Validation loss: 6.146, Accuracy: 2.41%
[23,    10] loss: 5.319
[23,    20] loss: 5.341
[23,    30] loss: 5.426
[23,    40] loss: 5.432
[23,    50] loss: 5.431
[23,    60] loss: 5.477
[23,    70] loss: 5.476
[23,    80] loss: 5.447
[23,    90] loss: 5.508
[23,   100] loss: 5.441
[23] Validation loss: 6.144, Accuracy: 2.50%
[24,    10] loss: 5.316
[24,    20] loss: 5.308
[24,    30] loss: 5.320
[24,    40] loss: 5.320
[24,    50] loss: 5.388
[24,    60] loss: 5.363
[24,    70] loss: 5.494
[24,    80] loss: 5.426
[24,    90] loss: 5.396
[24,   100] loss: 5.458
[24] Validation loss: 6.092, Accuracy: 2.61%
[25,    10] loss: 5.294
[25,    20] loss: 5.246
[25,    30] loss: 5.348
[25,    40] loss: 5.361
[25,    50] loss: 5.351
[25,    60] loss: 5.346
[25,    70] loss: 5.333
[25,    80] loss: 5.377
[25,    90] loss: 5.380
[25,   100] loss: 5.402
[25] Validation loss: 6.109, Accuracy: 2.68%
[26,    10] loss: 5.200
[26,    20] loss: 5.293
[26,    30] loss: 5.286
[26,    40] loss: 5.318
[26,    50] loss: 5.357
[26,    60] loss: 5.292
[26,    70] loss: 5.302
[26,    80] loss: 5.302
[26,    90] loss: 5.340
[26,   100] loss: 5.372
[26] Validation loss: 6.140, Accuracy: 2.69%
[27,    10] loss: 5.191
[27,    20] loss: 5.198
[27,    30] loss: 5.233
[27,    40] loss: 5.250
[27,    50] loss: 5.274
[27,    60] loss: 5.286
[27,    70] loss: 5.338
[27,    80] loss: 5.272
[27,    90] loss: 5.308
[27,   100] loss: 5.334
[27] Validation loss: 6.098, Accuracy: 2.74%
[28,    10] loss: 5.150
[28,    20] loss: 5.099
[28,    30] loss: 5.192
[28,    40] loss: 5.189
[28,    50] loss: 5.258
[28,    60] loss: 5.258
[28,    70] loss: 5.288
[28,    80] loss: 5.283
[28,    90] loss: 5.261
[28,   100] loss: 5.317
[28] Validation loss: 6.173, Accuracy: 2.84%
[29,    10] loss: 5.106
[29,    20] loss: 5.147
[29,    30] loss: 5.153
[29,    40] loss: 5.218
[29,    50] loss: 5.214
[29,    60] loss: 5.204
[29,    70] loss: 5.231
[29,    80] loss: 5.237
[29,    90] loss: 5.212
[29,   100] loss: 5.285
[29] Validation loss: 6.107, Accuracy: 2.90%
[30,    10] loss: 5.093
[30,    20] loss: 5.047
[30,    30] loss: 5.125
[30,    40] loss: 5.176
[30,    50] loss: 5.158
[30,    60] loss: 5.184
[30,    70] loss: 5.221
[30,    80] loss: 5.180
[30,    90] loss: 5.258
[30,   100] loss: 5.217
[30] Validation loss: 6.167, Accuracy: 2.89%
[31,    10] loss: 5.021
[31,    20] loss: 5.069
[31,    30] loss: 5.103
[31,    40] loss: 5.154
[31,    50] loss: 5.163
[31,    60] loss: 5.145
[31,    70] loss: 5.156
[31,    80] loss: 5.144
[31,    90] loss: 5.211
[31,   100] loss: 5.234
[31] Validation loss: 6.116, Accuracy: 2.90%
[32,    10] loss: 5.004
[32,    20] loss: 4.973
[32,    30] loss: 5.062
[32,    40] loss: 5.145
[32,    50] loss: 5.187
[32,    60] loss: 5.174
[32,    70] loss: 5.147
[32,    80] loss: 5.099
[32,    90] loss: 5.201
[32,   100] loss: 5.175
[32] Validation loss: 6.158, Accuracy: 2.92%
[33,    10] loss: 5.012
[33,    20] loss: 5.050
[33,    30] loss: 5.022
[33,    40] loss: 5.043
[33,    50] loss: 5.089
[33,    60] loss: 5.076
[33,    70] loss: 5.103
[33,    80] loss: 5.128
[33,    90] loss: 5.110
[33,   100] loss: 5.182
[33] Validation loss: 6.191, Accuracy: 2.91%
[34,    10] loss: 4.912
[34,    20] loss: 4.983
[34,    30] loss: 4.989
[34,    40] loss: 5.056
[34,    50] loss: 5.067
[34,    60] loss: 5.052
[34,    70] loss: 5.116
[34,    80] loss: 5.111
[34,    90] loss: 5.101
[34,   100] loss: 5.148
[34] Validation loss: 6.147, Accuracy: 3.02%
[35,    10] loss: 4.941
[35,    20] loss: 4.904
[35,    30] loss: 4.943
[35,    40] loss: 5.041
[35,    50] loss: 5.045
[35,    60] loss: 5.085
[35,    70] loss: 5.099
[35,    80] loss: 5.050
[35,    90] loss: 5.110
[35,   100] loss: 5.052
[35] Validation loss: 6.223, Accuracy: 2.93%
[36,    10] loss: 4.908
[36,    20] loss: 4.887
[36,    30] loss: 5.003
[36,    40] loss: 4.975
[36,    50] loss: 4.951
[36,    60] loss: 5.034
[36,    70] loss: 5.049
[36,    80] loss: 5.065
[36,    90] loss: 5.055
[36,   100] loss: 5.104
[36] Validation loss: 6.248, Accuracy: 2.98%
[37,    10] loss: 4.892
[37,    20] loss: 4.856
[37,    30] loss: 4.950
[37,    40] loss: 4.928
[37,    50] loss: 5.024
[37,    60] loss: 4.999
[37,    70] loss: 5.010
[37,    80] loss: 5.035
[37,    90] loss: 5.031
[37,   100] loss: 5.082
[37] Validation loss: 6.226, Accuracy: 2.95%
[38,    10] loss: 4.915
[38,    20] loss: 4.920
[38,    30] loss: 4.898
[38,    40] loss: 4.948
[38,    50] loss: 4.908
[38,    60] loss: 4.976
[38,    70] loss: 4.915
[38,    80] loss: 4.881
[38,    90] loss: 4.965
[38,   100] loss: 5.112
[38] Validation loss: 6.158, Accuracy: 3.18%
[39,    10] loss: 4.829
[39,    20] loss: 4.822
[39,    30] loss: 4.855
[39,    40] loss: 4.903
[39,    50] loss: 4.946
[39,    60] loss: 4.895
[39,    70] loss: 5.037
[39,    80] loss: 4.954
[39,    90] loss: 5.007
[39,   100] loss: 5.033
[39] Validation loss: 6.224, Accuracy: 3.20%
[40,    10] loss: 4.778
[40,    20] loss: 4.856
[40,    30] loss: 4.803
[40,    40] loss: 4.909
[40,    50] loss: 4.927
[40,    60] loss: 4.939
[40,    70] loss: 4.904
[40,    80] loss: 4.949
[40,    90] loss: 4.977
[40,   100] loss: 4.985
[40] Validation loss: 6.229, Accuracy: 3.23%
[41,    10] loss: 4.790
[41,    20] loss: 4.828
[41,    30] loss: 4.863
[41,    40] loss: 4.926
[41,    50] loss: 4.843
[41,    60] loss: 4.851
[41,    70] loss: 4.852
[41,    80] loss: 4.969
[41,    90] loss: 4.965
[41,   100] loss: 4.965
[41] Validation loss: 6.255, Accuracy: 3.06%
[42,    10] loss: 4.728
[42,    20] loss: 4.776
[42,    30] loss: 4.833
[42,    40] loss: 4.848
[42,    50] loss: 4.870
[42,    60] loss: 4.872
[42,    70] loss: 4.899
[42,    80] loss: 4.923
[42,    90] loss: 4.923
[42,   100] loss: 4.944
[42] Validation loss: 6.292, Accuracy: 3.06%
[43,    10] loss: 4.766
[43,    20] loss: 4.720
[43,    30] loss: 4.827
[43,    40] loss: 4.853
[43,    50] loss: 4.845
[43,    60] loss: 4.845
[43,    70] loss: 4.850
[43,    80] loss: 4.915
[43,    90] loss: 4.875
[43,   100] loss: 4.919
