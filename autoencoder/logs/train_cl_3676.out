Dataset is copied to /tmp
Start Training, use checkpointcheckpoints/tightrope_encoder_ep_14
[1,    10] loss: 6.716
[1,    20] loss: 6.691
[1,    30] loss: 6.689
[1,    40] loss: 6.685
[1,    50] loss: 6.687
[1,    60] loss: 6.690
[1,    70] loss: 6.684
[1,    80] loss: 6.689
[1,    90] loss: 6.691
[1,   100] loss: 6.688
[1,   110] loss: 6.684
[1,   120] loss: 6.684
[1,   130] loss: 6.683
[1,   140] loss: 6.678
[1,   150] loss: 6.674
[1,   160] loss: 6.680
[1,   170] loss: 6.691
[1,   180] loss: 6.689
[1,   190] loss: 6.687
[1,   200] loss: 6.688
[1,   210] loss: 6.691
[1,   220] loss: 6.686
[1,   230] loss: 6.681
[1,   240] loss: 6.686
[1,   250] loss: 6.673
[1,   260] loss: 6.691
[1,   270] loss: 6.688
[1,   280] loss: 6.689
[1,   290] loss: 6.683
[1,   300] loss: 6.689
[1,   310] loss: 6.691
[1,   320] loss: 6.672
[1,   330] loss: 6.667
[1,   340] loss: 6.686
[1,   350] loss: 6.685
[1,   360] loss: 6.666
[1,   370] loss: 6.669
[1,   380] loss: 6.664
[1,   390] loss: 6.647
[1,   400] loss: 6.634
[1] Validation loss: 6.647, Accuracy: 0.22%
[2,    10] loss: 6.610
[2,    20] loss: 6.621
[2,    30] loss: 6.627
[2,    40] loss: 6.644
[2,    50] loss: 6.632
[2,    60] loss: 6.602
[2,    70] loss: 6.587
[2,    80] loss: 6.628
[2,    90] loss: 6.617
[2,   100] loss: 6.581
[2,   110] loss: 6.614
[2,   120] loss: 6.577
[2,   130] loss: 6.595
[2,   140] loss: 6.584
[2,   150] loss: 6.556
[2,   160] loss: 6.591
[2,   170] loss: 6.559
[2,   180] loss: 6.561
[2,   190] loss: 6.594
[2,   200] loss: 6.587
[2,   210] loss: 6.577
[2,   220] loss: 6.549
[2,   230] loss: 6.555
[2,   240] loss: 6.572
[2,   250] loss: 6.605
[2,   260] loss: 6.579
[2,   270] loss: 6.559
[2,   280] loss: 6.521
[2,   290] loss: 6.577
[2,   300] loss: 6.541
[2,   310] loss: 6.558
[2,   320] loss: 6.527
[2,   330] loss: 6.509
[2,   340] loss: 6.531
[2,   350] loss: 6.557
[2,   360] loss: 6.557
[2,   370] loss: 6.510
[2,   380] loss: 6.542
[2,   390] loss: 6.520
[2,   400] loss: 6.555
[2] Validation loss: 6.497, Accuracy: 0.55%
[3,    10] loss: 6.433
[3,    20] loss: 6.459
[3,    30] loss: 6.459
[3,    40] loss: 6.453
[3,    50] loss: 6.462
[3,    60] loss: 6.445
[3,    70] loss: 6.426
[3,    80] loss: 6.463
[3,    90] loss: 6.402
[3,   100] loss: 6.415
[3,   110] loss: 6.453
[3,   120] loss: 6.431
[3,   130] loss: 6.507
[3,   140] loss: 6.464
[3,   150] loss: 6.453
[3,   160] loss: 6.449
[3,   170] loss: 6.437
[3,   180] loss: 6.460
[3,   190] loss: 6.426
[3,   200] loss: 6.464
[3,   210] loss: 6.432
[3,   220] loss: 6.438
[3,   230] loss: 6.477
[3,   240] loss: 6.431
[3,   250] loss: 6.413
[3,   260] loss: 6.424
[3,   270] loss: 6.444
[3,   280] loss: 6.377
[3,   290] loss: 6.450
[3,   300] loss: 6.447
[3,   310] loss: 6.372
[3,   320] loss: 6.421
[3,   330] loss: 6.449
[3,   340] loss: 6.410
[3,   350] loss: 6.445
[3,   360] loss: 6.432
[3,   370] loss: 6.358
[3,   380] loss: 6.440
[3,   390] loss: 6.391
[3,   400] loss: 6.406
[3] Validation loss: 6.424, Accuracy: 0.67%
[4,    10] loss: 6.370
[4,    20] loss: 6.317
[4,    30] loss: 6.318
[4,    40] loss: 6.297
[4,    50] loss: 6.304
[4,    60] loss: 6.288
[4,    70] loss: 6.314
[4,    80] loss: 6.213
[4,    90] loss: 6.249
[4,   100] loss: 6.269
[4,   110] loss: 6.258
[4,   120] loss: 6.281
[4,   130] loss: 6.301
[4,   140] loss: 6.295
[4,   150] loss: 6.266
[4,   160] loss: 6.303
[4,   170] loss: 6.294
[4,   180] loss: 6.283
[4,   190] loss: 6.259
[4,   200] loss: 6.347
[4,   210] loss: 6.333
[4,   220] loss: 6.322
[4,   230] loss: 6.334
[4,   240] loss: 6.356
[4,   250] loss: 6.327
[4,   260] loss: 6.269
[4,   270] loss: 6.343
[4,   280] loss: 6.364
[4,   290] loss: 6.331
[4,   300] loss: 6.296
[4,   310] loss: 6.386
[4,   320] loss: 6.330
[4,   330] loss: 6.300
[4,   340] loss: 6.316
[4,   350] loss: 6.359
[4,   360] loss: 6.260
[4,   370] loss: 6.319
[4,   380] loss: 6.246
[4,   390] loss: 6.261
[4,   400] loss: 6.285
[4] Validation loss: 6.367, Accuracy: 1.02%
[5,    10] loss: 6.149
[5,    20] loss: 6.148
[5,    30] loss: 6.174
[5,    40] loss: 6.161
[5,    50] loss: 6.195
[5,    60] loss: 6.203
[5,    70] loss: 6.164
[5,    80] loss: 6.121
[5,    90] loss: 6.206
[5,   100] loss: 6.187
[5,   110] loss: 6.217
[5,   120] loss: 6.269
[5,   130] loss: 6.194
[5,   140] loss: 6.192
[5,   150] loss: 6.173
[5,   160] loss: 6.117
[5,   170] loss: 6.238
[5,   180] loss: 6.220
[5,   190] loss: 6.207
[5,   200] loss: 6.198
[5,   210] loss: 6.217
[5,   220] loss: 6.185
[5,   230] loss: 6.149
[5,   240] loss: 6.199
[5,   250] loss: 6.262
[5,   260] loss: 6.193
[5,   270] loss: 6.242
[5,   280] loss: 6.175
[5,   290] loss: 6.233
[5,   300] loss: 6.183
[5,   310] loss: 6.224
[5,   320] loss: 6.223
[5,   330] loss: 6.250
[5,   340] loss: 6.281
[5,   350] loss: 6.257
[5,   360] loss: 6.224
[5,   370] loss: 6.143
[5,   380] loss: 6.187
[5,   390] loss: 6.229
[5,   400] loss: 6.167
[5] Validation loss: 6.396, Accuracy: 1.08%
[6,    10] loss: 6.068
[6,    20] loss: 6.083
[6,    30] loss: 6.022
[6,    40] loss: 6.147
[6,    50] loss: 6.110
[6,    60] loss: 6.074
[6,    70] loss: 6.059
[6,    80] loss: 6.145
[6,    90] loss: 6.101
[6,   100] loss: 6.094
[6,   110] loss: 6.099
[6,   120] loss: 6.147
[6,   130] loss: 6.024
[6,   140] loss: 6.049
[6,   150] loss: 6.068
[6,   160] loss: 6.051
[6,   170] loss: 6.116
[6,   180] loss: 6.057
[6,   190] loss: 6.151
[6,   200] loss: 6.101
[6,   210] loss: 6.130
[6,   220] loss: 6.121
[6,   230] loss: 6.159
[6,   240] loss: 6.152
[6,   250] loss: 6.061
[6,   260] loss: 6.100
[6,   270] loss: 6.108
[6,   280] loss: 6.098
[6,   290] loss: 6.057
[6,   300] loss: 6.088
[6,   310] loss: 6.160
[6,   320] loss: 6.105
[6,   330] loss: 6.137
[6,   340] loss: 6.100
[6,   350] loss: 6.074
[6,   360] loss: 6.146
[6,   370] loss: 6.050
[6,   380] loss: 6.144
[6,   390] loss: 6.026
[6,   400] loss: 6.090
[6] Validation loss: 6.303, Accuracy: 1.28%
[7,    10] loss: 5.863
[7,    20] loss: 5.896
[7,    30] loss: 5.877
[7,    40] loss: 5.926
[7,    50] loss: 5.917
[7,    60] loss: 6.002
[7,    70] loss: 5.898
[7,    80] loss: 5.910
[7,    90] loss: 5.989
[7,   100] loss: 5.911
[7,   110] loss: 5.972
[7,   120] loss: 6.008
[7,   130] loss: 5.987
[7,   140] loss: 5.979
[7,   150] loss: 5.998
[7,   160] loss: 5.946
[7,   170] loss: 5.965
[7,   180] loss: 5.889
[7,   190] loss: 5.962
[7,   200] loss: 6.067
[7,   210] loss: 5.979
[7,   220] loss: 6.040
[7,   230] loss: 5.975
[7,   240] loss: 5.914
[7,   250] loss: 6.009
[7,   260] loss: 5.995
[7,   270] loss: 6.032
[7,   280] loss: 6.056
[7,   290] loss: 5.996
[7,   300] loss: 5.953
[7,   310] loss: 6.028
[7,   320] loss: 6.053
[7,   330] loss: 5.953
[7,   340] loss: 6.040
[7,   350] loss: 6.039
[7,   360] loss: 5.945
[7,   370] loss: 6.009
[7,   380] loss: 6.035
[7,   390] loss: 6.003
[7,   400] loss: 5.999
[7] Validation loss: 6.314, Accuracy: 1.61%
[8,    10] loss: 5.756
[8,    20] loss: 5.819
[8,    30] loss: 5.843
[8,    40] loss: 5.687
[8,    50] loss: 5.808
[8,    60] loss: 5.829
[8,    70] loss: 5.736
[8,    80] loss: 5.908
[8,    90] loss: 5.788
[8,   100] loss: 5.809
[8,   110] loss: 5.853
[8,   120] loss: 5.818
[8,   130] loss: 5.860
[8,   140] loss: 5.847
[8,   150] loss: 5.838
[8,   160] loss: 5.814
[8,   170] loss: 5.786
[8,   180] loss: 5.868
[8,   190] loss: 5.875
[8,   200] loss: 5.913
[8,   210] loss: 5.861
[8,   220] loss: 5.876
[8,   230] loss: 5.943
[8,   240] loss: 5.899
[8,   250] loss: 5.841
[8,   260] loss: 5.861
[8,   270] loss: 5.855
[8,   280] loss: 5.841
[8,   290] loss: 5.836
[8,   300] loss: 5.793
[8,   310] loss: 5.994
[8,   320] loss: 5.923
[8,   330] loss: 5.902
[8,   340] loss: 5.977
[8,   350] loss: 5.921
[8,   360] loss: 5.927
[8,   370] loss: 5.864
[8,   380] loss: 5.883
[8,   390] loss: 5.976
[8,   400] loss: 5.903
[8] Validation loss: 6.360, Accuracy: 1.61%
[9,    10] loss: 5.596
[9,    20] loss: 5.583
[9,    30] loss: 5.573
[9,    40] loss: 5.587
[9,    50] loss: 5.552
[9,    60] loss: 5.724
[9,    70] loss: 5.787
[9,    80] loss: 5.620
[9,    90] loss: 5.704
[9,   100] loss: 5.697
[9,   110] loss: 5.729
[9,   120] loss: 5.700
[9,   130] loss: 5.634
[9,   140] loss: 5.751
[9,   150] loss: 5.773
[9,   160] loss: 5.789
[9,   170] loss: 5.708
[9,   180] loss: 5.777
[9,   190] loss: 5.786
[9,   200] loss: 5.720
[9,   210] loss: 5.762
[9,   220] loss: 5.747
[9,   230] loss: 5.781
[9,   240] loss: 5.667
[9,   250] loss: 5.706
[9,   260] loss: 5.671
[9,   270] loss: 5.758
[9,   280] loss: 5.785
[9,   290] loss: 5.709
[9,   300] loss: 5.735
[9,   310] loss: 5.821
[9,   320] loss: 5.634
[9,   330] loss: 5.812
[9,   340] loss: 5.739
[9,   350] loss: 5.780
[9,   360] loss: 5.694
[9,   370] loss: 5.781
[9,   380] loss: 5.836
[9,   390] loss: 5.798
[9,   400] loss: 5.732
[9] Validation loss: 6.410, Accuracy: 1.77%
[10,    10] loss: 5.512
[10,    20] loss: 5.396
[10,    30] loss: 5.361
[10,    40] loss: 5.448
[10,    50] loss: 5.474
[10,    60] loss: 5.557
[10,    70] loss: 5.567
[10,    80] loss: 5.527
[10,    90] loss: 5.517
[10,   100] loss: 5.494
[10,   110] loss: 5.512
[10,   120] loss: 5.607
[10,   130] loss: 5.550
[10,   140] loss: 5.511
[10,   150] loss: 5.538
[10,   160] loss: 5.528
[10,   170] loss: 5.671
[10,   180] loss: 5.600
[10,   190] loss: 5.679
[10,   200] loss: 5.543
[10,   210] loss: 5.679
[10,   220] loss: 5.644
[10,   230] loss: 5.568
[10,   240] loss: 5.599
[10,   250] loss: 5.572
[10,   260] loss: 5.571
[10,   270] loss: 5.634
[10,   280] loss: 5.570
[10,   290] loss: 5.532
[10,   300] loss: 5.628
[10,   310] loss: 5.654
[10,   320] loss: 5.600
[10,   330] loss: 5.570
[10,   340] loss: 5.686
[10,   350] loss: 5.567
[10,   360] loss: 5.708
[10,   370] loss: 5.638
[10,   380] loss: 5.554
[10,   390] loss: 5.585
[10,   400] loss: 5.561
[10] Validation loss: 6.461, Accuracy: 1.82%
[11,    10] loss: 5.292
[11,    20] loss: 5.165
[11,    30] loss: 5.293
[11,    40] loss: 5.236
[11,    50] loss: 5.196
[11,    60] loss: 5.219
[11,    70] loss: 5.382
[11,    80] loss: 5.299
[11,    90] loss: 5.278
[11,   100] loss: 5.365
[11,   110] loss: 5.401
[11,   120] loss: 5.479
[11,   130] loss: 5.380
[11,   140] loss: 5.366
[11,   150] loss: 5.449
[11,   160] loss: 5.450
[11,   170] loss: 5.462
[11,   180] loss: 5.362
[11,   190] loss: 5.458
[11,   200] loss: 5.505
[11,   210] loss: 5.366
[11,   220] loss: 5.510
[11,   230] loss: 5.390
[11,   240] loss: 5.491
[11,   250] loss: 5.483
[11,   260] loss: 5.398
[11,   270] loss: 5.454
[11,   280] loss: 5.446
[11,   290] loss: 5.391
[11,   300] loss: 5.567
[11,   310] loss: 5.392
[11,   320] loss: 5.361
[11,   330] loss: 5.534
[11,   340] loss: 5.464
[11,   350] loss: 5.467
[11,   360] loss: 5.501
[11,   370] loss: 5.468
[11,   380] loss: 5.518
[11,   390] loss: 5.597
[11,   400] loss: 5.428
[11] Validation loss: 6.647, Accuracy: 1.74%
